{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification benchmarks: `ZSL`, `Finetuned BERT`, `Unprompted GPT`, `Prompted GPT` and `Finetuned GPT` \n",
    "\n",
    "GPT models can also be used for classification tasks. Here I'm putting together a classification benchmark by comparing a ZSL, a finetuned BERT and finetuned / prompted GPT models to see how they perform. I'll try to leverage transfer learning only, meaning I won't be training models (except for GPT SFT)\n",
    "\n",
    "OpenAI docs: \n",
    "- https://platform.openai.com/docs/guides/fine-tuning\n",
    "- https://platform.openai.com/docs/guides/fine-tuning/advanced-usage\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Fine-tuned_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import credentials\n",
    "import json\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials.openai_api\n",
    "\n",
    "import openai\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Sentiment dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_reviews_multi (C:/Users/Rabay_Kristof/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('amazon_reviews_multi', 'en', split = 'validation',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Needed cupcake rings, ended up with breast mil...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Star. This is the band I received.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good washer. Great product especially if you l...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Needed cupcake rings, ended up with breast mil...  negative\n",
       "1             One Star. This is the band I received.  negative\n",
       "2  Good washer. Great product especially if you l...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "\n",
    "data['review'] = data.apply(lambda x: x['review_title'] + '. ' + x['review_body'], axis = 1)\n",
    "\n",
    "data = data[data['stars'] != 3]\n",
    "data['sentiment'] = data['stars'].apply(lambda x: 'positive' if x >= 4 else 'negative')\n",
    "\n",
    "data.drop(labels = ['review_id', 'product_id', 'reviewer_id', 'language', 'review_title', 'review_body', 'stars', 'product_category'], axis = 1, inplace = True)\n",
    "data = data.sample(frac = 0.125, random_state=43)\n",
    "data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "print(data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Zero-Shot-Classifier\n",
    "\n",
    "Model: `MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_name, tokenizer=tokenizer, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = ['positive', 'negative']\n",
    "sequence_to_classify = data['review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 15s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ZSL_output = classifier(sequence_to_classify, candidate_labels, multi_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Needed cupcake rings, ended up with breast milk steam bags- very unhappy. If I could give this 0 stars I would. Itâ€™s not at all what we ordered. Needed these cupcake rings for my daughters birthday party tomorrow and instead I am left with breast pump and breast milk accessory micro steam bags. Wtf.',\n",
       " 'labels': ['negative', 'positive'],\n",
       " 'scores': [0.9748134016990662, 0.02518662065267563]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZSL_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ZSL_output:\n",
    "    i['labels'] = i['labels'][0]\n",
    "    i['scores'] = i['scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>labels</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Needed cupcake rings, ended up with breast mil...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.974813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Star. This is the band I received.</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.885268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good washer. Great product especially if you l...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.738286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment    labels   \n",
       "0  Needed cupcake rings, ended up with breast mil...  negative  negative  \\\n",
       "1             One Star. This is the band I received.  negative  positive   \n",
       "2  Good washer. Great product especially if you l...  positive  positive   \n",
       "\n",
       "     scores  \n",
       "0  0.974813  \n",
       "1  0.885268  \n",
       "2  0.738286  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZSL_output = pd.DataFrame(ZSL_output)\n",
    "\n",
    "ZSL_results = data.merge(ZSL_output, left_on = 'review', right_on = 'sequence').drop(labels = ['sequence'], axis = 1)\n",
    "ZSL_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       253\n",
      "    positive       0.87      0.92      0.89       247\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.89      0.89      0.89       500\n",
      "weighted avg       0.89      0.89      0.89       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ZSL_results['sentiment'], ZSL_results['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred - Neg</th>\n",
       "      <th>Pred - Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True - Neg</th>\n",
       "      <td>219</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True - Pos</th>\n",
       "      <td>20</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pred - Neg  Pred - Pos\n",
       "True - Neg         219          34\n",
       "True - Pos          20         227"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(ZSL_results['sentiment'], ZSL_results['labels'], labels = ['negative', 'positive']),\n",
    "             columns = ['Pred - Neg', 'Pred - Pos'], \n",
    "             index=['True - Neg', 'True - Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FineTuned BERT\n",
    "\n",
    "Model: `nlptown/bert-base-multilingual-uncased-sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a372c96b4d2847779f8050986eaefbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b632b5a4284c41bc2fa302c9933365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dd306c473e4483bbc89721d24989bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a807cb7488474fb3b4d1bd9b617a2a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4603c67cdde54c249d6769047df38a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model = 'nlptown/bert-base-multilingual-uncased-sentiment', use_fast=False)\n",
    "tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 40s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FT_BERT_output = pipe(sequence_to_classify, **tokenizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': '1 star', 'score': 0.9395105838775635}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FT_BERT_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Needed cupcake rings, ended up with breast mil...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.939511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Star. This is the band I received.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.993209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good washer. Great product especially if you l...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.787920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment     label   \n",
       "0  Needed cupcake rings, ended up with breast mil...  negative  negative  \\\n",
       "1             One Star. This is the band I received.  negative  negative   \n",
       "2  Good washer. Great product especially if you l...  positive  positive   \n",
       "\n",
       "      score  \n",
       "0  0.939511  \n",
       "1  0.993209  \n",
       "2  0.787920  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer = {'1 star' : 'negative', \n",
    "            '2 stars' : 'negative',\n",
    "            '3 stars' : 'negative',  \n",
    "            '4 stars' : 'positive',  \n",
    "            '5 stars' : 'positive'}\n",
    "FT_BERT_output = pd.DataFrame(FT_BERT_output).replace(replacer)\n",
    "\n",
    "FT_BERT_results = pd.concat([data, FT_BERT_output], axis = 1)\n",
    "FT_BERT_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       253\n",
      "    positive       0.97      0.90      0.93       247\n",
      "\n",
      "    accuracy                           0.94       500\n",
      "   macro avg       0.94      0.94      0.94       500\n",
      "weighted avg       0.94      0.94      0.94       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(FT_BERT_results['sentiment'], FT_BERT_results['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred - Neg</th>\n",
       "      <th>Pred - Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True - Neg</th>\n",
       "      <td>245</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True - Pos</th>\n",
       "      <td>24</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pred - Neg  Pred - Pos\n",
       "True - Neg         245           8\n",
       "True - Pos          24         223"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(FT_BERT_results['sentiment'], FT_BERT_results['label'], labels = ['negative', 'positive']),\n",
    "             columns = ['Pred - Neg', 'Pred - Pos'], \n",
    "             index=['True - Neg', 'True - Pos'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot less false positives, a little more FNs (but that may be due to 3 stars mapped to negative, while they should really be neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unprompted `GPT` model\n",
    "\n",
    "Unprompted here refers to 'Zero Shot', meaning to examples are given in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = OpenAI(model_name=\"text-davinci-003\", temperature = 0, max_tokens = 1, top_p = 1.0)\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature = 0, max_tokens = 1, top_p = 1.0)\n",
    "\n",
    "template = \"\"\"Decide whether a product review's sentiment is positive or negative. Only predict positive or negative.\n",
    "Product review: {review}\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"review\"], template=template)\n",
    "\n",
    "chain = LLMChain(llm = llm, prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decide whether a product review's sentiment is positive or negative. Only predict positive or negative.\n",
      "Product review: I hated this TV\n",
      "Sentiment:\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "REVIEW = 'I hated this TV'\n",
    "\n",
    "print(prompt.format(review = REVIEW))\n",
    "print(chain.run(REVIEW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dcaa5764183f595f6e9d19190922bc5d in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ca33f76389e9af6294ef7e870be72bf3 in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e60bed76fc72472f217d8a2719765817 in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3eb1558497b382c9ae674cf2072d01b6 in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ba8cdb2b42e5b978502eb79c964abc91 in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 696c4e77a19ab117dec276298b8665cf in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 95aa080c7bf8e47fa7795736ac9e65be in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7766943af5d234827f4d72734fdf1bd9 in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a0b20d7bae5fdec211b340ad93c2ae4e in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 8dea628e2213cbd9673fff6b5d9a8360 in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.11 s\n",
      "Wall time: 10min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GPT_unprompted_output = [chain.run(i).lower().strip() for i in sequence_to_classify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Needed cupcake rings, ended up with breast mil...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Star. This is the band I received.</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good washer. Great product especially if you l...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment     label\n",
       "0  Needed cupcake rings, ended up with breast mil...  negative  negative\n",
       "1             One Star. This is the band I received.  negative  negative\n",
       "2  Good washer. Great product especially if you l...  positive  positive"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_unprompted_results = pd.concat([data, pd.Series(GPT_unprompted_output, name = 'label')], axis = 1)\n",
    "GPT_unprompted_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Unassembled. The picture shown is of an assemb...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>a gift. Bought for my mother in law</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Be careful on the print size. It is slightly s...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Works well. The warmer works really well. The ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Ok. For the price serviceable</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Worth reading. Beautifully written. Missing de...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>It works.... Well... to lower your pH more qui...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Almost fits. The nylon material feels sturdier...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Confused. Hi, I lost my AirPod case so I bough...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>nice set. Nice set. Set is smaller than I thou...</td>\n",
       "      <td>positive</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Need more info. It would be nice to know what ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>It's okay. I thought it would be bigger in the...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Not great not bad. Its ok, I probably would ha...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>The material wasn't what I thought but still n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Not bad but..! Fast delivery. everything is go...</td>\n",
       "      <td>positive</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Old bootloader, reflash it for a better experi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment    label\n",
       "23   Unassembled. The picture shown is of an assemb...  positive  neutral\n",
       "30                 a gift. Bought for my mother in law  positive  neutral\n",
       "56   Be careful on the print size. It is slightly s...  positive  neutral\n",
       "77   Works well. The warmer works really well. The ...  positive    mixed\n",
       "87                       Ok. For the price serviceable  positive  neutral\n",
       "89   Worth reading. Beautifully written. Missing de...  positive  neutral\n",
       "106  It works.... Well... to lower your pH more qui...  positive  neutral\n",
       "196  Almost fits. The nylon material feels sturdier...  positive  neutral\n",
       "227  Confused. Hi, I lost my AirPod case so I bough...  negative  neutral\n",
       "255  nice set. Nice set. Set is smaller than I thou...  positive    mixed\n",
       "357  Need more info. It would be nice to know what ...  negative  neutral\n",
       "366  It's okay. I thought it would be bigger in the...  negative  neutral\n",
       "377  Not great not bad. Its ok, I probably would ha...  positive  neutral\n",
       "464  The material wasn't what I thought but still n...  positive  neutral\n",
       "480  Not bad but..! Fast delivery. everything is go...  positive    mixed\n",
       "496  Old bootloader, reflash it for a better experi...  positive  neutral"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_unprompted_results[~GPT_unprompted_results['label'].isin(['positive', 'negative'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "negative    258\n",
       "positive    226\n",
       "neutral      13\n",
       "mixed         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_unprompted_results['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_unprompted_results = GPT_unprompted_results[GPT_unprompted_results['label'].isin(['positive', 'negative'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.97      0.96       250\n",
      "    positive       0.97      0.94      0.95       234\n",
      "\n",
      "    accuracy                           0.95       484\n",
      "   macro avg       0.96      0.95      0.95       484\n",
      "weighted avg       0.95      0.95      0.95       484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(GPT_unprompted_results['sentiment'], GPT_unprompted_results['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred - Neg</th>\n",
       "      <th>Pred - Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True - Neg</th>\n",
       "      <td>243</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True - Pos</th>\n",
       "      <td>15</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pred - Neg  Pred - Pos\n",
       "True - Neg         243           7\n",
       "True - Pos          15         219"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(GPT_unprompted_results['sentiment'], GPT_unprompted_results['label'], labels = ['negative', 'positive']),\n",
    "             columns = ['Pred - Neg', 'Pred - Pos'], \n",
    "             index=['True - Neg', 'True - Pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even tho I asked the model to only predict positive or negative, on 13 occasions it predicted neutral, for 3 samples it predicted mixed. This is fine, most items are categorized as expected, and these neutral-mixed elements are correctly labeled as they have been. They really do not seem neither pos nor neg.\n",
    "\n",
    "Accounting for only the pos-neg items, unprompted GPT is the best model so far, better than a fine tuned BERT...\n",
    "\n",
    "Let's see if adding few-shots helps the model further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prompted `GPT` model\n",
    "\n",
    "Prompted here refers to 'Few Shot', meaning a couple of examples are given in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openAI_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
